{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7eb6e2-0a1b-42ea-8127-a51f13b4b4b0",
   "metadata": {},
   "source": [
    "# LibRAG Proof of Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3934dc57-c4c3-4892-bcf4-bce4aa5c48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8848a3a2-6be4-40f3-87ee-0c9dc099117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24d843-3692-49d5-8167-af46cf4a1f5a",
   "metadata": {},
   "source": [
    "### We are going to ensure that we have our data downloaded from the SCC.\n",
    "### We are going to download one interval of the full text, as well as the entire metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50d8c5f-dfea-454f-860e-13315a9c2fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../EDA Phase/bpl-digital-commonwealth/ft_13_checkpoint_10_133.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# replace with sample_full_text.json\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../EDA Phase/bpl-digital-commonwealth/ft_13_checkpoint_10_133.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m full_text \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../EDA Phase/bpl-digital-commonwealth/ft_13_checkpoint_10_133.json'"
     ]
    }
   ],
   "source": [
    "# replace with sample_full_text.json\n",
    "file = open(\"\")\n",
    "\n",
    "full_text = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567c6f4-1f82-4cfe-aa51-7f4a3bacf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d31b31-2c2a-40ae-99b6-5502395f8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path for metadata file on SCC: /projectnb/sparkgrp/ml-bpl-rag-data/full_data/bpl_data.json\n",
    "meta = open(\"\")\n",
    "bpl_metadata = json.load(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05e8ae-71f6-4ab3-b2fa-0193b77d6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_text['commonwealth:w3764603d']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f92651-0ff8-4ec7-b454-446e83e9f1d9",
   "metadata": {},
   "source": [
    "### Embedding a paragraph using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255817ec-711d-4888-81f5-6374c59e8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # Load a pre-trained Sentence-BERT model\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# # Example paragraph\n",
    "# paragraph = full_text['commonwealth:w3764603d']['text']\n",
    "# paragraph_embedding = model.encode(paragraph)\n",
    "\n",
    "# # Output: a vector representation of the paragraph\n",
    "# print(paragraph_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe50d1-9efb-405f-aec4-5091dace7222",
   "metadata": {},
   "source": [
    "### Setting up a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1e05d-35ca-45e7-af73-b5ea8d26199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain openai faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3033fe3-995e-46d5-86f4-5eda6a7e266a",
   "metadata": {},
   "source": [
    "#### After ensuring we have the necessary dependencies, we are going to make our retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e509e10-d10b-465c-83ba-e7ba9828f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "\n",
    "class ToyRetriever(BaseRetriever):\n",
    "    \"\"\"A toy retriever that contains the top k documents that contain the user query.\n",
    "\n",
    "    This retriever only implements the sync method _get_relevant_documents.\n",
    "\n",
    "    If the retriever were to involve file access or network access, it could benefit\n",
    "    from a native async implementation of `_aget_relevant_documents`.\n",
    "\n",
    "    As usual, with Runnables, there's a default async implementation that's provided\n",
    "    that delegates to the sync implementation running on another thread.\n",
    "    \"\"\"\n",
    "\n",
    "    documents: List[Document]\n",
    "    \"\"\"List of documents to retrieve from.\"\"\"\n",
    "    k: int\n",
    "    \"\"\"Number of top results to return\"\"\"\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[str]:\n",
    "        matching_documents = []\n",
    "        for document in documents:\n",
    "            if len(matching_documents) >= self.k:\n",
    "                return matching_documents\n",
    "\n",
    "            if query.lower() in document.page_content.lower():\n",
    "                matching_documents.append(document.metadata['title'])\n",
    "        return matching_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c55ae-c7a5-4aec-9fe5-d79ff6cc0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bpl_metadata['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e29caa-9e83-4ddf-a206-53b66012c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc415a0f-6e2e-4b2d-8355-62a569806380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84b8ed-2f7b-4a1c-bb95-693d9ca8a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes = pd.json_normalize(df['attributes'])\n",
    "df_attributes = pd.concat([df.drop(columns=['attributes']), df_attributes], axis=1)\n",
    "df_attributes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed31425-0d0d-46e7-ae69-45637110e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes.to_csv(\"metadata_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7759e-36d6-455a-a1e4-bafcb2041f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes.loc[df_attributes[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b410-a7b0-4ef3-bbb8-2c240e568a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes = pd.read_csv(\"metadata_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b269a56-1e1a-4cc7-8dbf-a37ecd6222ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d1c2d-16ad-43a0-844a-72238901c07d",
   "metadata": {},
   "source": [
    "### Turn full text into Documents type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d83b93-6840-4618-ac40-1c7de9e5cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_title(text):\n",
    "    match = re.search(r'\\d+\\s+(.+?)\\n', text)\n",
    "\n",
    "    # Extracting and printing the title if there's a match\n",
    "    if match:\n",
    "        title = match.group(1)\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f5614-cc45-4fb4-9b13-1fd0361da1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the BPL data into a Document\n",
    "from langchain.schema import Document\n",
    "documents = []\n",
    "for doc in full_text:\n",
    "    title = get_title(str(df_attributes.loc[df_attributes[\"id\"] == doc, \"title_info_primary_tsi\"]))\n",
    "    ID = get_title(str(df_attributes.loc[df_attributes[\"id\"] == doc, \"id\"]))\n",
    "    abstract = str(df_attributes.loc[df_attributes[\"id\"] == doc, \"abstract_tsi\"])\n",
    "    title_subtitle = str(df_attributes.loc[df_attributes[\"id\"] == doc, \"title_info_primary_subtitle_tsi\"])\n",
    "    documents += [Document(page_content=full_text[doc]['text'], metadata={\"title\": title, \"abstract\": abstract, \"subtitle\": title_subtitle, \"ID\":ID})]\n",
    "    #documents += [Document(page_content=full_text[doc]['text'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdead1-b760-4766-a880-64c6df5d0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = ToyRetriever(documents=documents, k=1)\n",
    "# retriever.invoke(\"Richmond\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c69e08-181c-42aa-a1e7-5e0846053503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "!source poc_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5d467-7d3f-4c34-b0d6-ab2d19471d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a395f8b-82eb-4e01-bbbc-3852524444c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f8878-1967-4630-817a-9eb1d321701e",
   "metadata": {},
   "source": [
    "### Using Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f20d4-4870-44ae-be93-66b3e16d53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chmod('mydatabase.db', 0o666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53d93b-165e-4f9b-8a6f-cd9329551a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb==0.5.0\n",
    "#!pip install --upgrade openai langchain\n",
    "# !pip install --upgrade langchain langchain_community langchain_openai openai python-dotenv chromadb\n",
    "# !pip install --upgrade transformers\n",
    "#!pip install --upgrade transformers torchvision\n",
    "\n",
    "# !pip install openai==1.37.1\n",
    "# !pip install langchain==0.2.11\n",
    "# !pip install langchain-openai==0.1.19\n",
    "# !pip install langchain-community==0.2.10\n",
    "# !pip install langchain-experimental==0.0.63\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0c6e6-fb80-4b01-9673-a790017ce71b",
   "metadata": {},
   "source": [
    "Now we can embed our data into a Chroma vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281018a-089b-4ad0-8f4c-efb4667c8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load environment variables. Assumes that project contains .env file with API keys\n",
    "load_dotenv()\n",
    "\n",
    "import tempfile\n",
    "CHROMA_PATH = tempfile.mkdtemp()  # Use a temporary directory\n",
    "\n",
    "def main(documents):\n",
    "    generate_data_store(documents)\n",
    "\n",
    "\n",
    "def generate_data_store(documents):\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)\n",
    "\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def save_to_chroma(chunks):\n",
    "    # Clear out the database first.\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "        print(f\"Removed existing database at {CHROMA_PATH}.\")\n",
    "\n",
    "    # Create a new DB from the documents.\n",
    "    os.makedirs(CHROMA_PATH, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    #embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    try:\n",
    "        db = Chroma.from_documents(\n",
    "            chunks, embeddings, persist_directory=CHROMA_PATH\n",
    "        )\n",
    "        db.persist()\n",
    "        print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08316ec-6545-4af5-a92e-1f026f121e4f",
   "metadata": {},
   "source": [
    "### Making the Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd15c30-251e-4460-a598-9e1fcf7aa3f5",
   "metadata": {},
   "source": [
    "We'll download langserve to make a sample UI for our app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01faae-fdbf-420d-9b79-e1f31e84baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"langserve[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cf9f0-e116-4e3a-a33c-accdf4246332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# For LangServe\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langserve import add_routes\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "\n",
    "# copy from above\n",
    "CHROMA_PATH = \"/var/folders/xq/fj3st__56r54gz9tdvb7d2k40000gn/T/tmpcp1qkd0k\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LangSmith App\n",
    "# app = App()\n",
    "\n",
    "# @langsmith_route(\"/answer-question\")\n",
    "def main(query: str):\n",
    "    # Create CLI with a default value for Jupyter testing\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\n",
    "    args = parser.parse_args(args=[query])  # Add a default value here for testing\n",
    "    query_text = args.query_text\n",
    "\n",
    "    # Prepare the database\n",
    "    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    #embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "    for i in range(len(results)):\n",
    "        if len(results) == 0 or results[0][1] < 0.1:\n",
    "            print(f\"Unable to find matching results for \\\"{query_text}\\\"\")\n",
    "            print(results[0][1])\n",
    "            return\n",
    "\n",
    "    #print(results)\n",
    "    \n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    print(prompt)\n",
    "\n",
    "    model = ChatOpenAI()\n",
    "    response_text = model.predict(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"title\") + \": \" + str(doc.metadata.get(\"ID\")) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\n\\nSources: {sources}\"\n",
    "    # response with context, sources, and answer to my query\n",
    "    print(formatted_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query1 = \"Who did Z.B Oakes receive a letter from?\"\n",
    "    query2 = \"What did Henry M. Sikes say about India Goods?\"\n",
    "    query3 = \"What are some of the most controversial topics in this database?\"\n",
    "    query4 = \"What happened in World War II?\"\n",
    "    query5 = \"Who critiqued India Goods?\"\n",
    "    query6 = \"Tell me about Barnstable Public Schools\"\n",
    "    #query7 = \"What did Thos. L Gelzia talk about in their letter to Mr Z. B. Oakes, but not in the Tocsin of Liberty?\"\n",
    "    queries = [query1, query2, query3, query4, query5, query6]\n",
    "    # print(\"-------------------New Query-------------------\")\n",
    "    # for query in queries:\n",
    "    #     main(query)\n",
    "    #     print(\"-------------------New Query-------------------\")\n",
    "    main(query1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba8e8f-14e3-48c0-9fc8-c07328271da3",
   "metadata": {},
   "source": [
    "# Notes from Gardos\n",
    "\n",
    "These are the list of fields, if you need any clarification about these fields ask about them.\n",
    "\n",
    "Vectorize all of the fields\n",
    "\n",
    "Give this to the LLM as a preface prompt.\n",
    "\n",
    "Maybe two vector stores?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
